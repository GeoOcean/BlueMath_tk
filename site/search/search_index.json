{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to BlueMath","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>\u251c\u2500\u2500 bluemath_tk\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 colors.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 datasets.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 launchers.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sketch_tk.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 core\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 data.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 models.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prueba.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 utils.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bathy.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 downloaders.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extraction.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 datamining\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 kma.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 lhs.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 mda.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pca.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prueba.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 som.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 distributions\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 copula.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gev.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gpd.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 poisson.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 pot.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 interp\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 analogs.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gps.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 rbf.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 predictor\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 awt.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dwt.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 indices.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 itca.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 iwt.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 risk\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 damage.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pcrafi.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 riskscapetools.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tc\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 graffitiwaves.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 parameterization.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 qtcrain.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 skytcwaves.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tracks.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 vortex.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tide\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 harmonic.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ttide.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 utide.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 topo-bathy\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 profiles.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 waves\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 climate.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 estela.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 greenswell.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 partitioning.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 snakes.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 superpoint.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 wrappers\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 cgwave.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 delft3d.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 lisflood.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 schism.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 swan.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 swash.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 xbeach.py\n\u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 datamining\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test_mda.py\n\u251c\u2500\u2500 demos\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 datamining\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 kma.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 mda.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 api.md\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 index.md\n\u251c\u2500\u2500 logs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 MDA_2024-11-05.log\n\u251c\u2500\u2500 LICENSE.txt\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 setup.py\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>Project: Bluemath{toolkit} File: mda.py Description: Maximum Dissimilarity Algorithm Author: GeoOcean Research Group, Universidad de Cantabria Created Date: 19 January 2024 License: MIT</p> Repository: https://github.com/GeoOcean/BlueMath_tk.git"},{"location":"api/#bluemath_tk.datamining.mda.MDA","title":"<code>MDA</code>","text":"<p>               Bases: <code>BlueMathModel</code></p> <p>Maximum Dissimilarity Algorithm (MDA) class.</p> <p>This class performs the MDA algorithm on a given dataframe.</p> <p>Attributes:</p> Name Type Description <code>num_centers</code> <code>int</code> <p>The number of centers to use in the MDA algorithm.</p> <code>_data</code> <code>DataFrame</code> <p>The input data.</p> <code>_normalized_data</code> <code>DataFrame</code> <p>The normalized input data.</p> <code>data_variables</code> <code>list</code> <p>A list of all data variables.</p> <code>directional_variables</code> <code>list</code> <p>A list with directional variables.</p> <code>custom_scale_factor</code> <code>dict</code> <p>A dictionary of custom scale factors.</p> <code>scale_factor</code> <code>dict</code> <p>A dictionary of scale factors.</p> <code>centroids</code> <code>DataFrame</code> <p>The selected centroids.</p> <code>normalized_centroids</code> <code>DataFrame</code> <p>The selected normalized centroids.</p> <code>centroid_iterative_indices</code> <code>list</code> <p>A list of iterative indices of the centroids.</p> <code>centroid_real_indices</code> <code>list</code> <p>A list of real indices of the centroids.</p> Notes <pre><code>This class is designed to perform the MDA algorithm.\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from bluemath_tk.datamining import MDA\n&gt;&gt;&gt; data = pd.DataFrame(\n...     {\n...         'Hs': np.random.rand(1000) * 7,\n...         'Tp': np.random.rand(1000) * 20,\n...         'Dir': np.random.rand(1000) * 360\n...     }\n... )\n&gt;&gt;&gt; mda = MDA(num_centers=10)\n&gt;&gt;&gt; mda.fit(\n...     data=data,\n...     directional_variables=['Dir'],\n...     custom_scale_factor={'Dir': [0, 360]},\n... )\n</code></pre> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>class MDA(BlueMathModel):\n    \"\"\"\n    Maximum Dissimilarity Algorithm (MDA) class.\n\n    This class performs the MDA algorithm on a given dataframe.\n\n    Attributes\n    ----------\n    num_centers : int\n        The number of centers to use in the MDA algorithm.\n    _data : pd.DataFrame\n        The input data.\n    _normalized_data : pd.DataFrame\n        The normalized input data.\n    data_variables : list\n        A list of all data variables.\n    directional_variables : list\n        A list with directional variables.\n    custom_scale_factor : dict\n        A dictionary of custom scale factors.\n    scale_factor : dict\n        A dictionary of scale factors.\n    centroids : pd.DataFrame\n        The selected centroids.\n    normalized_centroids : pd.DataFrame\n        The selected normalized centroids.\n    centroid_iterative_indices : list\n        A list of iterative indices of the centroids.\n    centroid_real_indices : list\n        A list of real indices of the centroids.\n\n    Notes\n    -----\n        This class is designed to perform the MDA algorithm.\n\n    Examples\n    --------\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from bluemath_tk.datamining import MDA\n        &gt;&gt;&gt; data = pd.DataFrame(\n        ...     {\n        ...         'Hs': np.random.rand(1000) * 7,\n        ...         'Tp': np.random.rand(1000) * 20,\n        ...         'Dir': np.random.rand(1000) * 360\n        ...     }\n        ... )\n        &gt;&gt;&gt; mda = MDA(num_centers=10)\n        &gt;&gt;&gt; mda.fit(\n        ...     data=data,\n        ...     directional_variables=['Dir'],\n        ...     custom_scale_factor={'Dir': [0, 360]},\n        ... )\n    \"\"\"\n\n    def __init__(self, num_centers: int) -&gt; None:\n        \"\"\"\n        Initializes the MDA class.\n\n        Parameters\n        ----------\n        num_centers : int\n            The number of centers to use in the MDA algorithm.\n            Must be greater than 0.\n\n        Raises\n        ------\n        ValueError\n            If num_centers is not greater than 0.\n        \"\"\"\n\n        super().__init__()\n        self.set_logger_name(name=self.__class__.__name__)\n        if num_centers &gt; 0:\n            self.num_centers = int(num_centers)\n        else:\n            raise ValueError(\"Variable num_centers must be &gt; 0\")\n        # NOTE: Below, all class attributes are instantiated\n        self._data: pd.DataFrame = pd.DataFrame()\n        self._normalized_data: pd.DataFrame = pd.DataFrame()\n        self.data_variables: list = []\n        self.directional_variables: list = []\n        self.custom_scale_factor: dict = {}\n        self.scale_factor: dict = {}\n        self.centroids: pd.DataFrame = pd.DataFrame()\n        self.normalized_centroids: pd.DataFrame = pd.DataFrame()\n        self.centroid_iterative_indices: list = []\n        self.centroid_real_indices: list = []\n\n    def _normalized_distance(\n        self, array_to_compare: np.ndarray, all_rest_data: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Calculate the normalized distance between the array_to_compare and all_rest_data.\n\n        Parameters:\n        - array_to_compare (np.ndarray): The array to compare against.\n        - all_rest_data (np.ndarray): The rest of the data.\n\n        Returns:\n        - np.ndarray: An array of squared Euclidean distances between the two arrays for each row.\n\n        Raises:\n        - MDAError: If the function is NOT called before or during fitting.\n\n        Notes:\n        - The function assumes that the data_variables, directional_variables, and scale_factor\n        attributes have been set.\n        - The function calculates the squared sum of differences for each row.\n        - The calculation for directional variables is different, as it considers the minimum\n        distance between the absolute difference and the maximum scale factor minus the\n        absolute difference, effectively \"wrapping around\" the scale factor range.\n        \"\"\"\n\n        if (\n            not self.data_variables\n            or not self.directional_variables\n            or not self.scale_factor\n        ):\n            raise MDAError(\n                \"_normalized_distance must be called after or during fitting, not before.\"\n            )\n\n        diff = np.zeros(all_rest_data.shape)\n\n        # Calculate differences for columns\n        ix = 0\n        for data_var in self.data_variables:\n            if data_var in self.directional_variables:\n                distance = np.absolute(array_to_compare[:, ix] - all_rest_data[:, ix])\n                diff[:, ix] = (\n                    np.minimum(distance, self.scale_factor.get(data_var)[1] - distance)\n                    * 2\n                )\n            else:\n                diff[:, ix] = array_to_compare[:, ix] - all_rest_data[:, ix]\n            ix = ix + 1\n\n        # Compute the squared sum of differences for each row\n        dist = np.sum(diff**2, axis=1)\n\n        return dist\n\n    def _nearest_indices(self):\n        \"\"\"\n        Compute nearest centroid index for each data point.\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        nearest_indices_array : numpy.ndarray\n            Array of nearest centroid indices for each data point.\n\n        Notes:\n        - This function assumes that the normalized_centroids and _normalized_data\n        attributes have been set.\n        - The function calculates the squared sum of differences for each data point\n        and each centroid.\n        \"\"\"\n\n        if self.normalized_centroids.empty or self._normalized_data.empty:\n            raise MDAError(\n                \"_nearest_indices must be called after or during fitting, not before.\"\n            )\n        # Compute distances and store nearest distance index\n        nearest_indices_array = np.zeros(self.normalized_centroids.shape[0], dtype=int)\n\n        for i in range(self.normalized_centroids.shape[0]):\n            rep = np.repeat(\n                np.expand_dims(self.normalized_centroids.values[i, :], axis=0),\n                self._normalized_data.values.shape[0],\n                axis=0,\n            )\n            ndist = self._normalized_distance(\n                array_to_compare=rep, all_rest_data=self._normalized_data.values\n            )\n\n            nearest_indices_array[i] = np.nanargmin(ndist)\n\n        return nearest_indices_array\n\n    @validate_data_mda\n    def fit(\n        self,\n        data: pd.DataFrame,\n        directional_variables: List[str],\n        custom_scale_factor: dict,\n    ):\n        \"\"\"\n        Fit the Maximum Dissimilarity Algorithm (MDA) to the provided data.\n\n        This method initializes centroids for the MDA algorithm using the provided\n        dataframe, directional variables, and custom scale factor. It normalizes the\n        data, iteratively selects centroids based on maximum dissimilarity, and\n        denormalizes the centroids before returning them.\n\n        Parameters\n        ----------\n        data : pd.DataFrame\n            The input data to be used for the MDA algorithm.\n        directional_variables : List[str]\n            A list of names of the directional variables within the data.\n        custom_scale_factor : dict\n            A dictionary specifying custom scale factors for normalization.\n\n        Returns\n        -------\n        pd.DataFrame\n            The calculated centroids of the dataset.\n\n        Notes\n        -----\n        - The function assumes that the data is validated by the `validate_data_mda`\n        decorator before execution.\n        - The method logs the progress of centroid initialization.\n        \"\"\"\n\n        self._data = data.copy()\n        self.data_variables = list(self._data.columns)\n        self.directional_variables = directional_variables\n        self.custom_scale_factor = custom_scale_factor\n\n        self.logger.info(\n            f\"\\nmda parameters: {self._data.shape[0]} --&gt; {self.num_centers}\\n\"\n        )\n\n        # Normalize provided data with instantiated custom_scale_factor\n        self._normalized_data, self.scale_factor = self.normalize(\n            data=self._data, custom_scale_factor=self.custom_scale_factor\n        )\n\n        # [DEPRECATED] Select the point with the maximum value in the first column of pandas dataframe\n        # seed = normalized_data[normalized_data.columns[0]].idxmax()\n        # Select the point with the maximum summed value\n        seed = self._normalized_data.sum(axis=1).idxmax()\n\n        # Initialize centroids subset\n        subset = np.array(\n            [self._normalized_data.values[seed]]\n        )  # The row that starts as seed\n        train = np.delete(self._normalized_data.values, seed, axis=0)\n\n        # Repeat until we have the desired num_centers\n        n_c = 1\n        while n_c &lt; self.num_centers:\n            m2 = subset.shape[0]\n            if m2 == 1:\n                xx2 = np.repeat(subset, train.shape[0], axis=0)\n                d_last = self._normalized_distance(\n                    array_to_compare=xx2, all_rest_data=train\n                )\n            else:\n                xx = np.array([subset[-1, :]])\n                xx2 = np.repeat(xx, train.shape[0], axis=0)\n                d_prev = self._normalized_distance(\n                    array_to_compare=xx2, all_rest_data=train\n                )\n                d_last = np.minimum(d_prev, d_last)\n\n            qerr, bmu = np.nanmax(d_last), np.nanargmax(d_last)\n\n            if not np.isnan(qerr):\n                self.centroid_iterative_indices.append(bmu)\n                subset = np.append(subset, np.array([train[bmu, :]]), axis=0)\n                train = np.delete(train, bmu, axis=0)\n                d_last = np.delete(d_last, bmu, axis=0)\n\n                # Log\n                fmt = \"0{0}d\".format(len(str(self.num_centers)))\n                self.logger.info(\n                    \"   MDA centroids: {1:{0}}/{2:{0}}\".format(\n                        fmt, subset.shape[0], self.num_centers\n                    )\n                )\n\n            n_c = subset.shape[0]\n\n        # De-normalize scalar and directional data\n        self.normalized_centroids = pd.DataFrame(subset, columns=self.data_variables)\n        self.centroids = self.denormalize(\n            normalized_data=self.normalized_centroids, scale_factor=self.scale_factor\n        )\n\n        # TODO: use the normalized centroids and the norm_data to avoid rounding errors.\n        # Calculate the real indices of the centroids\n        self.centroid_real_indices = self._nearest_indices()\n\n        return self.centroids\n\n    def nearest_centroid_indices(self, data_q: np.ndarray):\n        \"\"\"\n        Calculate the index of the nearest centroid to each data point in `data_q`.\n\n        Parameters\n        ----------\n        data_q : numpy.ndarray\n            The input data points. Can be a 1D or 2D array.\n\n        Returns\n        -------\n        ix_near_cent : numpy.ndarray\n            An array containing the index of the nearest centroid for each data point.\n\n        Raises\n        ------\n        MDAError\n            If centroids have not been calculated beforehand using the `.run` method.\n\n        Notes\n        -----\n        - This method assumes that the centroids have been calculated beforehand using the `.run` method.\n        - The normalization of the data points is performed using the `normalize` method with a custom scale factor.\n        - The distance between each data point and the centroids is calculated using the `_normalized_distance` method.\n        - The index of the nearest centroid for each data point is determined by finding the minimum distance.\n        \"\"\"\n\n        # Reshape if only one data point was selected\n        if len(np.shape(data_q)) == 1:\n            data_q = data_q.reshape(1, -1)\n\n        # Normalize data point\n        data_q_pd = pd.DataFrame(data_q, columns=self.data_variables)\n        data_q_norm, b = self.normalize(\n            data=data_q_pd,\n            custom_scale_factor=self.scale_factor,\n        )\n\n        # Check centroids were calculated beforehand\n        if len(self.centroids) == 0:\n            raise MDAError(\n                \"Centroids have not been calculated, first apply .run method\"\n            )\n\n        # Compute distances to centroids and store nearest distance index\n        ix_near_cent = np.zeros(data_q_norm.values.shape[0], dtype=int)\n        for i in range(data_q_norm.values.shape[0]):\n            norm_dists_centroids = self._normalized_distance(\n                self.normalized_centroids.values,\n                np.repeat(\n                    np.expand_dims(data_q_norm.values[i, :], axis=0),\n                    self.normalized_centroids.values.shape[0],\n                    axis=0,\n                ),\n            )\n            ix_near_cent[i] = np.nanargmin(norm_dists_centroids)\n\n        return ix_near_cent\n\n    def nearest_centroid(self, data_q: np.ndarray):\n        \"\"\"\n        Determine the nearest centroid for each data point in the provided dataset.\n\n        Parameters\n        ----------\n        data_q : numpy.ndarray\n            An array of data points for which the nearest centroid is to be determined.\n\n        Returns\n        -------\n        numpy.ndarray\n            An array of the nearest centroids corresponding to each data point in `data_q`.\n\n        Notes\n        -----\n        - This method assumes that centroids have been calculated and are available.\n        - The distance between each data point and the centroids is calculated using\n          the `_normalized_distance` method. The index of the nearest centroid for each\n          data point is determined by finding the minimum distance.\n        \"\"\"\n\n        ix_near_cents = self.nearest_centroid_indices(data_q)\n        nearest_cents = self.centroids.values[ix_near_cents]\n\n        return nearest_cents\n</code></pre>"},{"location":"api/#bluemath_tk.datamining.mda.MDA.__init__","title":"<code>__init__(num_centers)</code>","text":"<p>Initializes the MDA class.</p> <p>Parameters:</p> Name Type Description Default <code>num_centers</code> <code>int</code> <p>The number of centers to use in the MDA algorithm. Must be greater than 0.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If num_centers is not greater than 0.</p> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>def __init__(self, num_centers: int) -&gt; None:\n    \"\"\"\n    Initializes the MDA class.\n\n    Parameters\n    ----------\n    num_centers : int\n        The number of centers to use in the MDA algorithm.\n        Must be greater than 0.\n\n    Raises\n    ------\n    ValueError\n        If num_centers is not greater than 0.\n    \"\"\"\n\n    super().__init__()\n    self.set_logger_name(name=self.__class__.__name__)\n    if num_centers &gt; 0:\n        self.num_centers = int(num_centers)\n    else:\n        raise ValueError(\"Variable num_centers must be &gt; 0\")\n    # NOTE: Below, all class attributes are instantiated\n    self._data: pd.DataFrame = pd.DataFrame()\n    self._normalized_data: pd.DataFrame = pd.DataFrame()\n    self.data_variables: list = []\n    self.directional_variables: list = []\n    self.custom_scale_factor: dict = {}\n    self.scale_factor: dict = {}\n    self.centroids: pd.DataFrame = pd.DataFrame()\n    self.normalized_centroids: pd.DataFrame = pd.DataFrame()\n    self.centroid_iterative_indices: list = []\n    self.centroid_real_indices: list = []\n</code></pre>"},{"location":"api/#bluemath_tk.datamining.mda.MDA.fit","title":"<code>fit(data, directional_variables, custom_scale_factor)</code>","text":"<p>Fit the Maximum Dissimilarity Algorithm (MDA) to the provided data.</p> <p>This method initializes centroids for the MDA algorithm using the provided dataframe, directional variables, and custom scale factor. It normalizes the data, iteratively selects centroids based on maximum dissimilarity, and denormalizes the centroids before returning them.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input data to be used for the MDA algorithm.</p> required <code>directional_variables</code> <code>List[str]</code> <p>A list of names of the directional variables within the data.</p> required <code>custom_scale_factor</code> <code>dict</code> <p>A dictionary specifying custom scale factors for normalization.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The calculated centroids of the dataset.</p> Notes <ul> <li>The function assumes that the data is validated by the <code>validate_data_mda</code> decorator before execution.</li> <li>The method logs the progress of centroid initialization.</li> </ul> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>@validate_data_mda\ndef fit(\n    self,\n    data: pd.DataFrame,\n    directional_variables: List[str],\n    custom_scale_factor: dict,\n):\n    \"\"\"\n    Fit the Maximum Dissimilarity Algorithm (MDA) to the provided data.\n\n    This method initializes centroids for the MDA algorithm using the provided\n    dataframe, directional variables, and custom scale factor. It normalizes the\n    data, iteratively selects centroids based on maximum dissimilarity, and\n    denormalizes the centroids before returning them.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        The input data to be used for the MDA algorithm.\n    directional_variables : List[str]\n        A list of names of the directional variables within the data.\n    custom_scale_factor : dict\n        A dictionary specifying custom scale factors for normalization.\n\n    Returns\n    -------\n    pd.DataFrame\n        The calculated centroids of the dataset.\n\n    Notes\n    -----\n    - The function assumes that the data is validated by the `validate_data_mda`\n    decorator before execution.\n    - The method logs the progress of centroid initialization.\n    \"\"\"\n\n    self._data = data.copy()\n    self.data_variables = list(self._data.columns)\n    self.directional_variables = directional_variables\n    self.custom_scale_factor = custom_scale_factor\n\n    self.logger.info(\n        f\"\\nmda parameters: {self._data.shape[0]} --&gt; {self.num_centers}\\n\"\n    )\n\n    # Normalize provided data with instantiated custom_scale_factor\n    self._normalized_data, self.scale_factor = self.normalize(\n        data=self._data, custom_scale_factor=self.custom_scale_factor\n    )\n\n    # [DEPRECATED] Select the point with the maximum value in the first column of pandas dataframe\n    # seed = normalized_data[normalized_data.columns[0]].idxmax()\n    # Select the point with the maximum summed value\n    seed = self._normalized_data.sum(axis=1).idxmax()\n\n    # Initialize centroids subset\n    subset = np.array(\n        [self._normalized_data.values[seed]]\n    )  # The row that starts as seed\n    train = np.delete(self._normalized_data.values, seed, axis=0)\n\n    # Repeat until we have the desired num_centers\n    n_c = 1\n    while n_c &lt; self.num_centers:\n        m2 = subset.shape[0]\n        if m2 == 1:\n            xx2 = np.repeat(subset, train.shape[0], axis=0)\n            d_last = self._normalized_distance(\n                array_to_compare=xx2, all_rest_data=train\n            )\n        else:\n            xx = np.array([subset[-1, :]])\n            xx2 = np.repeat(xx, train.shape[0], axis=0)\n            d_prev = self._normalized_distance(\n                array_to_compare=xx2, all_rest_data=train\n            )\n            d_last = np.minimum(d_prev, d_last)\n\n        qerr, bmu = np.nanmax(d_last), np.nanargmax(d_last)\n\n        if not np.isnan(qerr):\n            self.centroid_iterative_indices.append(bmu)\n            subset = np.append(subset, np.array([train[bmu, :]]), axis=0)\n            train = np.delete(train, bmu, axis=0)\n            d_last = np.delete(d_last, bmu, axis=0)\n\n            # Log\n            fmt = \"0{0}d\".format(len(str(self.num_centers)))\n            self.logger.info(\n                \"   MDA centroids: {1:{0}}/{2:{0}}\".format(\n                    fmt, subset.shape[0], self.num_centers\n                )\n            )\n\n        n_c = subset.shape[0]\n\n    # De-normalize scalar and directional data\n    self.normalized_centroids = pd.DataFrame(subset, columns=self.data_variables)\n    self.centroids = self.denormalize(\n        normalized_data=self.normalized_centroids, scale_factor=self.scale_factor\n    )\n\n    # TODO: use the normalized centroids and the norm_data to avoid rounding errors.\n    # Calculate the real indices of the centroids\n    self.centroid_real_indices = self._nearest_indices()\n\n    return self.centroids\n</code></pre>"},{"location":"api/#bluemath_tk.datamining.mda.MDA.nearest_centroid","title":"<code>nearest_centroid(data_q)</code>","text":"<p>Determine the nearest centroid for each data point in the provided dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data_q</code> <code>ndarray</code> <p>An array of data points for which the nearest centroid is to be determined.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of the nearest centroids corresponding to each data point in <code>data_q</code>.</p> Notes <ul> <li>This method assumes that centroids have been calculated and are available.</li> <li>The distance between each data point and the centroids is calculated using   the <code>_normalized_distance</code> method. The index of the nearest centroid for each   data point is determined by finding the minimum distance.</li> </ul> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>def nearest_centroid(self, data_q: np.ndarray):\n    \"\"\"\n    Determine the nearest centroid for each data point in the provided dataset.\n\n    Parameters\n    ----------\n    data_q : numpy.ndarray\n        An array of data points for which the nearest centroid is to be determined.\n\n    Returns\n    -------\n    numpy.ndarray\n        An array of the nearest centroids corresponding to each data point in `data_q`.\n\n    Notes\n    -----\n    - This method assumes that centroids have been calculated and are available.\n    - The distance between each data point and the centroids is calculated using\n      the `_normalized_distance` method. The index of the nearest centroid for each\n      data point is determined by finding the minimum distance.\n    \"\"\"\n\n    ix_near_cents = self.nearest_centroid_indices(data_q)\n    nearest_cents = self.centroids.values[ix_near_cents]\n\n    return nearest_cents\n</code></pre>"},{"location":"api/#bluemath_tk.datamining.mda.MDA.nearest_centroid_indices","title":"<code>nearest_centroid_indices(data_q)</code>","text":"<p>Calculate the index of the nearest centroid to each data point in <code>data_q</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_q</code> <code>ndarray</code> <p>The input data points. Can be a 1D or 2D array.</p> required <p>Returns:</p> Name Type Description <code>ix_near_cent</code> <code>ndarray</code> <p>An array containing the index of the nearest centroid for each data point.</p> <p>Raises:</p> Type Description <code>MDAError</code> <p>If centroids have not been calculated beforehand using the <code>.run</code> method.</p> Notes <ul> <li>This method assumes that the centroids have been calculated beforehand using the <code>.run</code> method.</li> <li>The normalization of the data points is performed using the <code>normalize</code> method with a custom scale factor.</li> <li>The distance between each data point and the centroids is calculated using the <code>_normalized_distance</code> method.</li> <li>The index of the nearest centroid for each data point is determined by finding the minimum distance.</li> </ul> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>def nearest_centroid_indices(self, data_q: np.ndarray):\n    \"\"\"\n    Calculate the index of the nearest centroid to each data point in `data_q`.\n\n    Parameters\n    ----------\n    data_q : numpy.ndarray\n        The input data points. Can be a 1D or 2D array.\n\n    Returns\n    -------\n    ix_near_cent : numpy.ndarray\n        An array containing the index of the nearest centroid for each data point.\n\n    Raises\n    ------\n    MDAError\n        If centroids have not been calculated beforehand using the `.run` method.\n\n    Notes\n    -----\n    - This method assumes that the centroids have been calculated beforehand using the `.run` method.\n    - The normalization of the data points is performed using the `normalize` method with a custom scale factor.\n    - The distance between each data point and the centroids is calculated using the `_normalized_distance` method.\n    - The index of the nearest centroid for each data point is determined by finding the minimum distance.\n    \"\"\"\n\n    # Reshape if only one data point was selected\n    if len(np.shape(data_q)) == 1:\n        data_q = data_q.reshape(1, -1)\n\n    # Normalize data point\n    data_q_pd = pd.DataFrame(data_q, columns=self.data_variables)\n    data_q_norm, b = self.normalize(\n        data=data_q_pd,\n        custom_scale_factor=self.scale_factor,\n    )\n\n    # Check centroids were calculated beforehand\n    if len(self.centroids) == 0:\n        raise MDAError(\n            \"Centroids have not been calculated, first apply .run method\"\n        )\n\n    # Compute distances to centroids and store nearest distance index\n    ix_near_cent = np.zeros(data_q_norm.values.shape[0], dtype=int)\n    for i in range(data_q_norm.values.shape[0]):\n        norm_dists_centroids = self._normalized_distance(\n            self.normalized_centroids.values,\n            np.repeat(\n                np.expand_dims(data_q_norm.values[i, :], axis=0),\n                self.normalized_centroids.values.shape[0],\n                axis=0,\n            ),\n        )\n        ix_near_cent[i] = np.nanargmin(norm_dists_centroids)\n\n    return ix_near_cent\n</code></pre>"},{"location":"api/#bluemath_tk.datamining.mda.MDAError","title":"<code>MDAError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for MDA class.</p> Source code in <code>bluemath_tk/datamining/mda.py</code> <pre><code>class MDAError(Exception):\n    \"\"\"\n    Custom exception for MDA class.\n    \"\"\"\n\n    def __init__(self, message: str = \"MDA error occurred.\"):\n        self.message = message\n        super().__init__(self.message)\n</code></pre>"}]}